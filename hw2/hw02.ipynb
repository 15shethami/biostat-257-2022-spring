{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biostat 257 Homework 2\n",
    "\n",
    "**Due Apr 29 @ 11:59PM**\n",
    "\n",
    "Ami Sheth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.7.2\n",
      "Commit bf53498635 (2022-02-06 15:21 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin19.5.0)\n",
      "  CPU: Intel(R) Core(TM) i5-4260U CPU @ 1.40GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-12.0.1 (ORCJIT, haswell)\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "# import Pkg; Pkg.add(\"Images\")\n",
    "using BenchmarkTools, DelimitedFiles, Images, LinearAlgebra, Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Nonnegative Matrix Factorization\n",
    "\n",
    "Nonnegative matrix factorization (NNMF) was introduced by [Lee and Seung (1999)](https://www.nature.com/articles/44565) as an analog of principal components and vector quantization with applications in data compression and clustering. In this homework we consider algorithms for fitting NNMF and (optionally) high performance computing using graphical processing units (GPUs).\n",
    "\n",
    "<img src=\"./nnmf.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "In mathematical terms, one approximates a data matrix $\\mathbf{X} \\in \\mathbb{R}^{m \\times n}$ with nonnegative entries $x_{ij}$ by a product of two low-rank matrices $\\mathbf{V} \\in \\mathbb{R}^{m \\times r}$ and $\\mathbf{W} \\in \\mathbb{R}^{r \\times n}$ with nonnegative entries $v_{ik}$ and $w_{kj}$. Consider minimization of the squared Frobenius norm\n",
    "$$\n",
    "\tL(\\mathbf{V}, \\mathbf{W}) = \\|\\mathbf{X} - \\mathbf{V} \\mathbf{W}\\|_{\\text{F}}^2 = \\sum_i \\sum_j \\left(x_{ij} - \\sum_k v_{ik} w_{kj} \\right)^2, \\quad v_{ik} \\ge 0, w_{kj} \\ge 0,\n",
    "$$\n",
    "which should lead to a good factorization. Lee and Seung suggest an iterative algorithm with multiplicative updates\n",
    "$$\n",
    "v_{ik}^{(t+1)} = v_{ik}^{(t)} \\frac{\\sum_j x_{ij} w_{kj}^{(t)}}{\\sum_j b_{ij}^{(t)} w_{kj}^{(t)}}, \\quad \\text{where } b_{ij}^{(t)} = \\sum_k v_{ik}^{(t)} w_{kj}^{(t)},\n",
    "$$\n",
    "$$\n",
    "w_{kj}^{(t+1)} = w_{kj}^{(t)} \\frac{\\sum_i x_{ij} v_{ik}^{(t+1)}}{\\sum_i b_{ij}^{(t+1/2)} v_{ik}^{(t+1)}}, \\quad \\text{where } b_{ij}^{(t+1/2)} = \\sum_k v_{ik}^{(t+1)} w_{kj}^{(t)}\n",
    "$$\n",
    "that will drive the objective $L^{(t)} = L(\\mathbf{V}^{(t)}, \\mathbf{W}^{(t)})$ downhill. Superscript $t$ indicates iteration number. In following questions, efficiency (both speed and memory) will be the most important criterion when grading this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1 Develop code\n",
    "\n",
    "Implement the algorithm with arguments: $\\mathbf{X}$ (data, each row is a vectorized image), rank $r$, convergence tolerance, and optional starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "**Step 1: Prototyping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnmf_prototype (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nnmf_prototype(\n",
    "    X       :: Matrix{T}, \n",
    "    r       :: Integer;\n",
    "    maxiter :: Integer = 1000, \n",
    "    tolfun  :: Number = 1e-4,\n",
    "    V       :: Matrix{T} = rand(T, size(X, 1), r),\n",
    "    W       :: Matrix{T} = rand(T, r, size(X, 2)),\n",
    "    verbose :: Bool = false # display intermediate code\n",
    "    ) where T <: AbstractFloat\n",
    "    # implementation\n",
    "    obj = norm(X - V * W)^2 \n",
    "    if verbose # useful for debugging\n",
    "        println(\"iter = 0, obj = $obj\")\n",
    "    end\n",
    "    niter = maxiter # if condition never met, returns max iteration\n",
    "    for iter in 1:maxiter\n",
    "        # update V\n",
    "        V .= V .* (X * W') ./ (V * W * W')\n",
    "        # update W\n",
    "        W .= W .* (V' * X) ./ (V' * V * W)\n",
    "        # update obj\n",
    "        objold = obj\n",
    "        obj = norm(X - V * W)^2 \n",
    "        if verbose\n",
    "            println(\"iter = 0, obj = $obj\")\n",
    "        end\n",
    "        # check convergence\n",
    "        if abs(obj - objold) ≤ tolfun * (abs(objold) + 1)\n",
    "            niter = iter\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    if niter == maxiter\n",
    "        @warn \"maxiter reached without convergence\"\n",
    "    end\n",
    "    # Output\n",
    "    V, W, obj, niter\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ways to improve allocation: \n",
    "1. BLAS function for multiplication of matrices\n",
    "2. Order of multiplying matrices matters when more than 2; i.e. W by W^T first because r is low rank, so rxr is smaller\n",
    "3. Look at flop counts \n",
    "\n",
    "What does not matter:\n",
    "1. Scalars do not affect allocation\n",
    "2. Elementwise operations are fused into one loop so it does not cause allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Optimize code (benchmarking, profiling, ...)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnmf (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nnmf(\n",
    "    X       :: Matrix{T}, \n",
    "    r       :: Integer;\n",
    "    maxiter :: Integer = 1000, \n",
    "    tolfun  :: Number = 1e-4,\n",
    "    V       :: Matrix{T} = rand(T, size(X, 1), r),\n",
    "    W       :: Matrix{T} = rand(T, r, size(X, 2)),\n",
    "    verbose :: Bool = false\n",
    "    ) where T <: AbstractFloat\n",
    "    # implementation\n",
    "    if verbose\n",
    "        println(\"iter = 0, obj = $obj\")\n",
    "    end\n",
    "    niter = maxiter  \n",
    "    # preallocation for matrix multiplication \n",
    "    storageR = Matrix{T}(undef, r, r) # store V'V and WW' since both rxr\n",
    "    storageV1 = similar(V) # same dimension as V\n",
    "    storageV2 = similar(V)\n",
    "    storageW1 = similar(W) # same dimension as W\n",
    "    storageW2 = similar(W)\n",
    "    x2norm = norm(X)^2\n",
    "    # initial objective\n",
    "    obj = x2norm\n",
    "    # matrix multiplication needed for Frobenius norm\n",
    "    # better to write function here\n",
    "    mul!(storageR, transpose(V), V) # stores V'V (rxr)\n",
    "    mul!(storageW2, storageR, W) # stores V'VW (rxn)\n",
    "    mul!(storageW1, transpose(V), X) # stores V'X (rxn)\n",
    "    @inbounds for idx in eachindex(W)\n",
    "        obj = obj + (storageW2[idx] - 2storageW1[idx]) * W[idx]\n",
    "    end\n",
    "    for iter in 1:maxiter\n",
    "        # update V .= V .* (X * W') ./ (V * (W * W'))\n",
    "        mul!(storageR, W, transpose(W)) # stores WW' (rxr)\n",
    "        mul!(storageV2, V, storageR) # stores VWW' (mxr)\n",
    "        mul!(storageV1, X, transpose(W)) # store XW'(mxr)\n",
    "        V .= V .* storageV1 ./ storageV2\n",
    "        # update W .= W .* (V' * X) ./ ((V' * V) * W)\n",
    "        mul!(storageR, transpose(V), V) # stores V'V (rxr)\n",
    "        mul!(storageW2, storageR, W) # stores V'VW (rxn)\n",
    "        mul!(storageW1, transpose(V), X) # stores V'X (rxn)\n",
    "        objold = obj\n",
    "        # update obj\n",
    "        obj = x2norm\n",
    "        @inbounds for idx in eachindex(W)\n",
    "            obj = obj + (storageW2[idx] - 2storageW1[idx]) * W[idx]\n",
    "            W[idx] = W[idx] * storageW1[idx] / storageW2[idx]\n",
    "        end\n",
    "        if verbose\n",
    "            println(\"iter = 0, obj = $obj\")\n",
    "        end\n",
    "        # check convergence\n",
    "        if abs(obj - objold) ≤ tolfun * (abs(objold) + 1)\n",
    "            niter = iter\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    if niter == maxiter\n",
    "        @warn \"maxiter reached without convergence\"\n",
    "    end\n",
    "    # Output\n",
    "    V, W, obj, niter\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2 Data\n",
    "\n",
    "Database 1 from the [MIT Center for Biological and Computational Learning (CBCL)](http://cbcl.mit.edu) reduces to a matrix $\\mathbf{X}$ containing $m = 2,429$ gray-scale face images with $n = 19 \\times 19 = 361$ pixels per face. Each image (row) is scaled to have mean and standard deviation 0.25.  \n",
    "\n",
    "Read in the [`nnmf-2429-by-361-face.txt`](https://raw.githubusercontent.com/ucla-biostat-257/2022spring/master/hw/hw2/nnmf-2429-by-361-face.txt) file, e.g., using [`readdlm`](https://docs.julialang.org/en/v1/stdlib/DelimitedFiles/#Delimited-Files) function, and display a couple sample images, e.g., using the [Images.jl](https://juliaimages.org/stable/) package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHIAAAByCAAAAACqttqhAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAydJREFUaAW9wTFr3AUcx+EPyfc40oZrSogNh1JCQzlaQiQURdxcRHDwPbg7ODv5IsQX4OYglIK4SKGUaildQksJxnA2hMbjb45wzXmcCfKZ/lA6/54nN9Et9D4aoC6aojV0Da3SOkb30Sv0GDXoJtpFMzREoVwoF8qFcqFcDtAcnaInaA816CO0gm6iLXSIvqa1gsZolzd1USgXyoVyoVwolwV0iA7QBjqgdQ99hu6hL9B3tNZRQ2sZTVAXzVAoF8qFcqFcKJcZb/oSfYMGaIaeo2X0M/oX7aCP0bfoKprQmqEFFMqFcqFcKBfKZQ2NaH2PtlEH7aPL6IzWFfQANWiC+ugETWl1USgXyoVyoVwolw7qoVM0pTVBPXQD7aMFtERriO6iFbSMztCEVigXyoVyoVwol0/RI7SN+miGrqC/UR/9hUZoiHpoFe2gPmrQErpPK5QL5UK5UC6Uyw00RAN0HfXRHN1FY3SOOmgVnaItWhtoDY3QOlpFoVwoF8qFcqFcRuhzdIT6aBFdoD7aRRdogIa0eugW6qAtdILO0WsUyoVyoVwoF8rlFB2gd1EH9dAGOkO/oAG6jX5FHbSKPkTnaIymqEMrlAvlQrlQLpTLCK2iI3SBVtAAvYOOUR+toG30AzpCW+h3NEcNGqMjFMqFcqFcKBfK5QyN0BJq0Bw9RItoAT1AX6E9NEdj9BPaRGPUoAUUFMqFcqFcKBfKpYeCZqiPNtAYvUTvoSE6QMu0XqIf0Q66gy6hGa1QLpQL5UK5UC6HqIsW0RQ9Ro/QM3QJbaOr6BxtoT30FL1AD9EdNEHHKJQL5UK5UC6UyxCtoT56ie6jMdpEAzRAi+gE9dAMnaFDdI56aAMNUSgXyoVyoVwolzFq0FV0gP5DE7SLdtES2kR/oClv9xpdQ6eoQaFcKBfKhXKhXC6j52gdraGnvN0UvUBz3vQJmqITdBs9oBXKhXKhXCgXyuU1mqMRuoE2UBddQmfoOlpAY9RBe2gN/YNm6BX6k1YoF8qFcqFcKJc5rSfoGdpEH6ARalCDJqiLGnQH7aN1dIJ+Q/u0QrlQLpQL5UK5/wFd2bFZ/j51mAAAAABJRU5ErkJggg==",
      "text/plain": [
       "19×19 reinterpret(reshape, Gray{Float64}, ::Matrix{Float64}) with eltype Gray{Float64}:\n",
       " Gray{Float64}(0.14815)   …  Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.018294)     Gray{Float64}(0.027569)\n",
       " Gray{Float64}(0.027569)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)          Gray{Float64}(0.0090181)\n",
       " Gray{Float64}(0.083222)     Gray{Float64}(0.036844)\n",
       " Gray{Float64}(0.10177)   …  Gray{Float64}(0.064671)\n",
       " Gray{Float64}(0.38004)      Gray{Float64}(0.13887)\n",
       " Gray{Float64}(0.51917)      Gray{Float64}(0.30583)\n",
       " Gray{Float64}(0.43569)      Gray{Float64}(0.37076)\n",
       " Gray{Float64}(0.38004)      Gray{Float64}(0.37076)\n",
       " Gray{Float64}(0.29656)   …  Gray{Float64}(0.26873)\n",
       " Gray{Float64}(0.25946)      Gray{Float64}(0.28728)\n",
       " Gray{Float64}(0.31511)      Gray{Float64}(0.28728)\n",
       " Gray{Float64}(0.2038)       Gray{Float64}(0.19453)\n",
       " Gray{Float64}(0.083222)     Gray{Float64}(0.073946)\n",
       " Gray{Float64}(0.018294)  …  Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.064671)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.018294)     Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)          Gray{Float64}(0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = readdlm(\"nnmf-2429-by-361-face.txt\") \n",
    "colorview(Gray, reshape(X[1, :], 19, 19)) # each row is a face\n",
    "# goal: obtain a low rank approximation of the original faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHIAAAByCAAAAACqttqhAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAx1JREFUaAW9wUFr2wUcx+EP7TdryQyRrKV2KMWyrUzGvMjGYFBPQxBfgWdfw8DX4DvwrAg7CLJdRNlF8CSihBZdCIyOaukICX9XWkODfE5/KLLj73myhK6hB2gbdWhdRzfQVbSCFmiI/kQNeo7eQMvoCTpGoVwoF8qFcqFcFug5+hrdRidohNbQLhqgj9EEfY+eoj/QgtYGmtAK5UK5UC6UC+VyE+2jM/QrmtGaoB6aox10gL5CM7SBjmgdcVEoF8qFcqFcKJd9LvocPUR9dIJeoC56hgZohjbRLvqG1wnlQrlQLpQL5dJHM1oPaX2AfkS30E9ogUZoCX2BtlEPfcn/C+VCuVAulAvlsow6aI420RW0hzbQEJ2hhtYCfYq6qMPrhHKhXCgXyoVyuYcOaA3QFrqCfkM99ANqUIdWB62iNTRAy2iODlAoF8qFcqFcKJfbaIrW0TYaoBX0M5qiHjrlogGtu6iHGtTQCuVCuVAulAvl8gLdRw26iU7QHhqgBi2jHXRCa46uoXP0N+qhVdRDoVwoF8qFcqFcztErdBvtoC5aQ4/QM3QfvY/GqIMadAddQgM0R2O0iUK5UC6UC+VCuVxGl9ACNahBI7SH5ug99Al6hHbQEJ2hXbSCGrSCGhTKhXKhXCgXyuUQraFzdExrHV1HT9Bj9CGaoiEXHaIuatARWkKhXCgXyoVyoVwm6Bwto6voFtpDfbSBfkGfoRGtd1EXdVCDxuglalAoF8qFcqFcKJdzdIKmaBU9RS9QB91DIzREXbSO1tEIXUVztEAN+geFcqFcKBfKhXLpohkaoMfoCM3R2+gt9BG6gdbRETpGY/QKbaEGTWiFcqFcKBfKhXKZozW0hIboL1r7qI920D00RCM0RTO0jzbRXfQvOkOhXCgXyoVyoVxO0TtoCy3QKRqhV2iZ1ndogma0uugOuoweoG/R7yiUC+VCuVAulMsZGqM+rXPUR120g3poii6h5+gUNegMraJT9BKdolAulAvlQrlQLh10iNbRBDVoA22gQzRGc/Qm6qMVWlM0QEM0RjMUyoVyoVwoF8r9B/UzquhU4s5/AAAAAElFTkSuQmCC",
      "text/plain": [
       "19×19 reinterpret(reshape, Gray{Float64}, ::Matrix{Float64}) with eltype Gray{Float64}:\n",
       " Gray{Float64}(0.0082034)  …  Gray{Float64}(0.18099)\n",
       " Gray{Float64}(0.0)           Gray{Float64}(0.018367)\n",
       " Gray{Float64}(0.16066)       Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)           Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.059024)      Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.069188)   …  Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.2928)        Gray{Float64}(0.0082034)\n",
       " Gray{Float64}(0.47575)       Gray{Float64}(0.12001)\n",
       " Gray{Float64}(0.36394)       Gray{Float64}(0.17083)\n",
       " Gray{Float64}(0.35378)       Gray{Float64}(0.27247)\n",
       " Gray{Float64}(0.39444)    …  Gray{Float64}(0.31312)\n",
       " Gray{Float64}(0.2928)        Gray{Float64}(0.32329)\n",
       " Gray{Float64}(0.22165)       Gray{Float64}(0.27247)\n",
       " Gray{Float64}(0.21148)       Gray{Float64}(0.22165)\n",
       " Gray{Float64}(0.25214)       Gray{Float64}(0.22165)\n",
       " Gray{Float64}(0.23181)    …  Gray{Float64}(0.17083)\n",
       " Gray{Float64}(0.20132)       Gray{Float64}(0.089516)\n",
       " Gray{Float64}(0.17083)       Gray{Float64}(0.059024)\n",
       " Gray{Float64}(0.19116)       Gray{Float64}(0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorview(Gray, reshape(X[5, :], 19, 19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHIAAAByCAAAAACqttqhAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAy1JREFUaAW9wb9v1AUcx+FX6fugXHv02rNw0mBFQSIRQRPDYnR0ME7GP8LZ/8PFwdmYGB2d3TQMGmMgJDqgKIUWaEN/HdfWgxbz6vIlBh0/zxP+Vwu9iz5Eb6NddB19gX5DbbSGtlAbbdMI5UK5UC6UC+XCf5hDQzRAf6Ln0D76Fd1AKzxbF23TCOVCuVAulAvlwoFJdAa9g95Am+hr9A16Cw3Rp+h19BJaRy3UQVfRBNpFoVwoF8qFcqFcODBEd9FnNN5D59GP6CMak+gc+gvdQw/QSTRAPXQMhXKhXCgXyoVymUdLaArNoCk0hsKzDVEHddCr6CFqoxk0je6hUC6UC+VCuVAuU+gcehldQtNoHP1A42Man6Nl9D7aRSN0m8ZhdAWFcqFcKBfKhXKZRz3URSfQPFpBbRqP0SyNPdRBZ9AAzaIdNEKnUCgXyoVyoVwolwtoEk2hNmqho+gaOo6m0TSaQ7fQOI0emkCH0DrqoVAulAvlQrlQLl3URx10BO2hb9FNdBH1UAddQt+h79EHaAIdR1toD91CoVwoF8qFcqFcvkIX0QRaQ6voPDqJxlAfTaNpdBb9hO6iBfQiuo6uoHUUyoVyoVwoF8rlTXQK9VEPddAf6Gc0RFfRPFpFZ9Ej9Am6h+6jC+gMWkahXCgXyoVyoVyWUBfN0Wihv1EL7aAv0Rg6hTbQJbSJ+mgc3UEP0X0UyoVyoVwoF8rlDhpHIzSBNtATdBldR6dRC41QD51Ei6iDBmgRbaARCuVCuVAulAvlsoKOoGPoGuqgW+guGkMLaAtto2X0CG2icbSHBmgZraJQLpQL5UK5UC7baBMtokU0g26gE+gFNIFGqI820O9oCU2iIzQGaA2FcqFcKBfKhXLhwAAdQi10FC2hJfQLGkdtNODfJtFlNEC7aIRGKJQL5UK5UC6UCweGqI3mUB910QaNBbSNuug2jdfQCbSGNtFD9ACFcqFcKBfKhXLhKWuoj56gBbSFDqNtNId20SyaQc+jHbSPBmgV7aNQLpQL5UK5UC48ZQ/dRPtoB51Gj9EaGqJZ9ArqohE6jFbQOtqiEcqFcqFcKBfK/QOSIp+oD9TLOwAAAABJRU5ErkJggg==",
      "text/plain": [
       "19×19 reinterpret(reshape, Gray{Float64}, ::Matrix{Float64}) with eltype Gray{Float64}:\n",
       " Gray{Float64}(0.0)       …  Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)          Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)          Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)          Gray{Float64}(0.088149)\n",
       " Gray{Float64}(0.1071)       Gray{Float64}(0.13237)\n",
       " Gray{Float64}(0.15132)   …  Gray{Float64}(0.18291)\n",
       " Gray{Float64}(0.25871)      Gray{Float64}(0.29662)\n",
       " Gray{Float64}(0.4356)       Gray{Float64}(0.37242)\n",
       " Gray{Float64}(0.49877)      Gray{Float64}(0.2524)\n",
       " Gray{Float64}(0.145)        Gray{Float64}(0.056563)\n",
       " Gray{Float64}(0.34084)   …  Gray{Float64}(0.39138)\n",
       " Gray{Float64}(0.23345)      Gray{Float64}(0.30294)\n",
       " Gray{Float64}(0.12605)      Gray{Float64}(0.27767)\n",
       " Gray{Float64}(0.037612)     Gray{Float64}(0.17659)\n",
       " Gray{Float64}(0.0)          Gray{Float64}(0.1071)\n",
       " Gray{Float64}(0.0)       …  Gray{Float64}(0.081832)\n",
       " Gray{Float64}(0.0)          Gray{Float64}(0.0060253)\n",
       " Gray{Float64}(0.0)          Gray{Float64}(0.0)\n",
       " Gray{Float64}(0.0)          Gray{Float64}(0.0)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorview(Gray, reshape(X[50, :], 19, 19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.3 Correctness and efficiency\n",
    "\n",
    "Report the run times, using `@time`, of your function for fitting NNMF on the MIT CBCL face data set at ranks $r=10, 20, 30, 40, 50$. For ease of comparison (and grading), please start your algorithm with the provided $\\mathbf{V}^{(0)}$ (first $r$ columns of [`V0.txt`](https://raw.githubusercontent.com/ucla-biostat-257/2022spring/master/hw/hw2/V0.txt)) and $\\mathbf{W}^{(0)}$ (first $r$ rows of [`W0.txt`](https://raw.githubusercontent.com/ucla-biostat-257/2022spring/master/hw/hw2/W0.txt)) and stopping criterion\n",
    "$$\n",
    "\\frac{|L^{(t+1)} - L^{(t)}|}{|L^{(t)}| + 1} \\le 10^{-4}.\n",
    "$$\n",
    "\n",
    "**Hint**: When I run the following code using my own implementation of `nnmf`\n",
    "```julia\n",
    "for r in [10, 20, 30, 40, 50]\n",
    "    println(\"r=$r\")\n",
    "    V0 = V0full[:, 1:r]\n",
    "    W0 = W0full[1:r, :]\n",
    "    @time V, W, obj, niter = nnmf(X, r; V = V0, W = W0)\n",
    "    println(\"obj=$obj, niter=$niter\")\n",
    "end\n",
    "```\n",
    "the output is\n",
    "```\n",
    "r=10\n",
    "  1.047598 seconds (20 allocations: 6.904 MiB)\n",
    "obj=11730.38800985483, niter=239\n",
    "r=20\n",
    "  1.913147 seconds (20 allocations: 7.120 MiB)\n",
    "obj=8497.222317850326, niter=394\n",
    "r=30\n",
    "  2.434662 seconds (20 allocations: 7.336 MiB)\n",
    "obj=6621.627345486279, niter=482\n",
    "r=40\n",
    "  3.424469 seconds (22 allocations: 7.554 MiB)\n",
    "obj=5256.663870563529, niter=581\n",
    "r=50\n",
    "  4.480342 seconds (23 allocations: 7.774 MiB)\n",
    "obj=4430.201581697291, niter=698\n",
    "```\n",
    "Since my laptop is about 6-7 years old, I expect to see your run time shorter than mine. Your memory allocation should be less or equal to mine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50×361 Matrix{Float64}:\n",
       " 0.5634    0.32048   0.067202   0.25107   …  0.4476     0.12656   0.13688\n",
       " 0.71473   0.25423   0.084735   0.84327      0.20947    0.32729   0.43787\n",
       " 0.046351  0.041688  0.79152    0.8962       0.6786     0.17112   0.83691\n",
       " 0.76991   0.13366   0.0061026  0.70588      0.4457     0.012722  0.64244\n",
       " 0.56335   0.35408   0.62697    0.94923      0.073816   0.62934   0.58596\n",
       " 0.13659   0.82449   0.17183    0.051802  …  0.87725    0.86247   0.45418\n",
       " 0.2326    0.92296   0.73855    0.35246      0.015108   0.68424   0.15457\n",
       " 0.95628   0.97221   0.94922    0.59106      0.49038    0.52232   0.4399\n",
       " 0.82876   0.33257   0.95808    0.11028      0.66812    0.69979   0.57679\n",
       " 0.33585   0.59454   0.75948    0.26544      0.34689    0.071471  0.020196\n",
       " 0.87571   0.83349   0.83207    0.57283   …  0.34609    0.22545   0.2295\n",
       " 0.27631   0.10171   0.4809     0.10614      0.0039955  0.92647   0.27393\n",
       " 0.914     0.45783   0.32193    0.65607      0.1204     0.29447   0.88988\n",
       " ⋮                                        ⋱                       ⋮\n",
       " 0.30883   0.41147   0.64075    0.87004      0.20019    0.55648   0.7459\n",
       " 0.97866   0.74029   0.037366   0.97796      0.55272    0.3288    0.837\n",
       " 0.71393   0.78077   0.051596   0.25867   …  0.95825    0.89787   0.21096\n",
       " 0.35293   0.41894   0.0063373  0.43144      0.14756    0.93285   0.59017\n",
       " 0.46036   0.61322   0.91126    0.76635      0.67864    0.16147   0.93417\n",
       " 0.036917  0.4889    0.2838     0.03403      0.027589   0.79055   0.31241\n",
       " 0.74309   0.12138   0.82587    0.84609      0.52128    0.908     0.6062\n",
       " 0.74466   0.46317   0.38367    0.97784   …  0.78373    0.4644    0.54906\n",
       " 0.57612   0.81248   0.14814    0.65148      0.78202    0.26502   0.34613\n",
       " 0.65722   0.28434   0.78214    0.62961      0.054762   0.14826   0.23983\n",
       " 0.5275    0.15481   0.50847    0.26226      0.1513     0.048605  0.052235\n",
       " 0.027423  0.80658   0.33708    0.54062      0.887      0.15571   0.76327"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V0full = readdlm(\"V0.txt\")\n",
    "W0full = readdlm(\"W0.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.1185155250605055 0.02994050345509698 … 0.0028830808553836434 0.06420991048712604; 0.13176807592569617 0.0004309168162359832 … 0.014863431363093798 0.03502874558367169; … ; 0.05270583755824644 0.04794098005163979 … 0.1700196278798266 0.04626182097825304; 0.12933014679416052 0.019567810402128034 … 0.09435983264067124 0.029580777291877254], [3.385885235846814e-27 1.174537573868145e-27 … 0.2300193333797503 2.2801686250907805e-6; 0.010899790573386688 1.7007366080211221e-6 … 9.165787020780837e-15 5.134415347265115e-11; … ; 4.0722852963974885e-10 0.0001197464191754901 … 6.6113838164410616e-6 1.37989840473972e-12; 5.698509363463882e-10 6.980500700786509e-9 … 2.2318529440908972e-14 1.8764490698063353e-18], 11730.866905749992, 239)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 10\n",
    "V0 = V0full[:, 1:r]\n",
    "W0 = W0full[1:r, :]\n",
    "nnmf(X, r; V = V0, W = W0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.174767 seconds (12 allocations: 437.297 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.1185155250605055 0.02994050345509698 … 0.0028830808553836434 0.06420991048712604; 0.13176807592569617 0.0004309168162359832 … 0.014863431363093798 0.03502874558367169; … ; 0.05270583755824644 0.04794098005163979 … 0.1700196278798266 0.04626182097825304; 0.12933014679416052 0.019567810402128034 … 0.09435983264067124 0.029580777291877254], [3.385885235846814e-27 1.174537573868145e-27 … 0.2300193333797503 2.2801686250907805e-6; 0.010899790573386688 1.7007366080211221e-6 … 9.165787020780837e-15 5.134415347265115e-11; … ; 4.0722852963974885e-10 0.0001197464191754901 … 6.6113838164410616e-6 1.37989840473972e-12; 5.698509363463882e-10 6.980500700786509e-9 … 2.2318529440908972e-14 1.8764490698063353e-18], 11730.866905749992, 239)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V0 = V0full[:, 1:r]\n",
    "W0 = W0full[1:r, :]\n",
    "@time nnmf(X, r; V = V0, W = W0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=10\n",
      "  1.131130 seconds (22 allocations: 437.641 KiB)\n",
      "obj=11730.866905749992, niter=239\n",
      "r=20\n",
      "  2.242477 seconds (22 allocations: 875.891 KiB)\n",
      "obj=8497.605595865527, niter=394\n",
      "r=30\n",
      "  3.580852 seconds (22 allocations: 1.285 MiB)\n",
      "obj=6621.9459684778, niter=482\n",
      "r=40\n",
      "  4.676658 seconds (24 allocations: 1.716 MiB)\n",
      "obj=5256.86629983215, niter=581\n",
      "r=50\n",
      "  7.135485 seconds (25 allocations: 2.149 MiB)\n",
      "obj=4430.36209731353, niter=698\n"
     ]
    }
   ],
   "source": [
    "V0 = V0full[:, 1:r]\n",
    "W0 = W0full[1:r, :]\n",
    "nnmf(X, r; V = V0, W = W0)\n",
    "\n",
    "for r in [10, 20, 30, 40, 50]\n",
    "    println(\"r=$r\")\n",
    "    V0 = V0full[:, 1:r]\n",
    "    W0 = W0full[1:r, :]\n",
    "    @time V, W, obj, niter = nnmf(X, r; V = V0, W = W0)\n",
    "    println(\"obj=$obj, niter=$niter\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.4 Non-uniqueness\n",
    "\n",
    "Choose an $r \\in \\{10, 20, 30, 40, 50\\}$ and start your algorithm from a different $\\mathbf{V}^{(0)}$ and $\\mathbf{W}^{(0)}$. Do you obtain the same objective value and $(\\mathbf{V}, \\mathbf{W})$? Explain what you find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.058981075055638224 0.14525209007122994 … 0.019055146210778362 0.07053298554909462; 0.004489426466693886 0.14816955761610148 … 0.0041909068195955705 0.04073934701123995; … ; 0.02112368252898036 0.003989718130885983 … 0.0018885614698087038 0.06539979614759503; 4.938926389647611e-5 0.12717549471004394 … 0.006553939033269752 0.026018142255132704], [0.08343350414395032 2.023563251255995e-7 … 1.6735275142115434e-16 4.008843253562877e-15; 1.9863288485978493e-15 4.545304585858992e-22 … 0.27820918282473767 0.23423504689982172; … ; 0.3526749465524293 0.5997881823823353 … 4.572575155398515e-18 4.040115662527214e-22; 5.553454536254431e-17 1.742428240709883e-16 … 3.4088360310866805e-5 3.7558878994914313e-13], 11766.631378380396, 212)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 10\n",
    "V1 = V0full[:, 2:(r + 1)]\n",
    "W1 = W0full[2: (r + 1), :]\n",
    "nnmf(X, r; V = V1, W = W1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, I do not obtain the same objective value and ($\\textbf{V}, \\textbf{W}$). The objective value, ($\\textbf{V}, \\textbf{W}$) depends on which iteration the stopping criterion is met. Convergence and objective value are around the same as the above example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.5 Fixed point\n",
    "\n",
    "For the same $r$, start your algorithm from $v_{ik}^{(0)} = w_{kj}^{(0)} = 1$ for all $i,j,k$. Do you obtain the same objective value and $(\\mathbf{V}, \\mathbf{W})$? Explain what you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2429×10 Matrix{Float64}:\n",
       " 0.0273734  0.0273734  0.0273734  …  0.0273734  0.0273734  0.0273734\n",
       " 0.0272069  0.0272069  0.0272069     0.0272069  0.0272069  0.0272069\n",
       " 0.0275595  0.0275595  0.0275595     0.0275595  0.0275595  0.0275595\n",
       " 0.0264271  0.0264271  0.0264271     0.0264271  0.0264271  0.0264271\n",
       " 0.0272624  0.0272624  0.0272624     0.0272624  0.0272624  0.0272624\n",
       " 0.0265809  0.0265809  0.0265809  …  0.0265809  0.0265809  0.0265809\n",
       " 0.0260185  0.0260185  0.0260185     0.0260185  0.0260185  0.0260185\n",
       " 0.0251604  0.0251604  0.0251604     0.0251604  0.0251604  0.0251604\n",
       " 0.0241206  0.0241206  0.0241206     0.0241206  0.0241206  0.0241206\n",
       " 0.0239623  0.0239623  0.0239623     0.0239623  0.0239623  0.0239623\n",
       " 0.0273784  0.0273784  0.0273784  …  0.0273784  0.0273784  0.0273784\n",
       " 0.0269211  0.0269211  0.0269211     0.0269211  0.0269211  0.0269211\n",
       " 0.0275334  0.0275334  0.0275334     0.0275334  0.0275334  0.0275334\n",
       " ⋮                                ⋱                        \n",
       " 0.0279663  0.0279663  0.0279663     0.0279663  0.0279663  0.0279663\n",
       " 0.0288318  0.0288318  0.0288318     0.0288318  0.0288318  0.0288318\n",
       " 0.0283638  0.0283638  0.0283638     0.0283638  0.0283638  0.0283638\n",
       " 0.0283359  0.0283359  0.0283359  …  0.0283359  0.0283359  0.0283359\n",
       " 0.0282879  0.0282879  0.0282879     0.0282879  0.0282879  0.0282879\n",
       " 0.0287806  0.0287806  0.0287806     0.0287806  0.0287806  0.0287806\n",
       " 0.0287673  0.0287673  0.0287673     0.0287673  0.0287673  0.0287673\n",
       " 0.028766   0.028766   0.028766      0.028766   0.028766   0.028766\n",
       " 0.0286082  0.0286082  0.0286082  …  0.0286082  0.0286082  0.0286082\n",
       " 0.0285394  0.0285394  0.0285394     0.0285394  0.0285394  0.0285394\n",
       " 0.0285202  0.0285202  0.0285202     0.0285202  0.0285202  0.0285202\n",
       " 0.0280309  0.0280309  0.0280309     0.0280309  0.0280309  0.0280309"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 10\n",
    "m, n = size(X)\n",
    "V2 = ones(m, r)\n",
    "W2 = ones(r, n)\n",
    "V, W, obj, niter = nnmf(X, r; V = V2, W = W2)\n",
    "# V, W columns are all the same "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, I do not obtain the same objective value and ($\\textbf{V}, \\textbf{W}$). The objective value is about the same as previous examples for the same r, but the number of iterations is only 4. Convergence appears to be faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.6 Interpret NNMF result\n",
    "\n",
    "Plot the basis images (rows of $\\mathbf{W}$) at rank $r=50$. What do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.065152683367589e-8 0.02391830987010448 … 0.0050275293945103005 0.030895205383236247; 2.066922665650733e-5 0.01676918953044336 … 0.0016843647387214 0.03357388284868296; … ; 0.013653571084018568 0.020407618225550362 … 8.933004101207235e-5 0.04512260292309185; 0.01821569164993885 0.009941879525504831 … 5.393742344944298e-6 0.00014298874864300805], [1.988389142207648e-64 1.2476690072002253e-53 … 2.7319238780356062e-14 8.879923560802795e-65; 5.008532883861646e-27 2.3803648259630052e-26 … 2.005876391414098e-32 4.4803366072845716e-61; … ; 3.6009667110863195e-15 2.707734064744678e-15 … 3.862314406203127e-22 2.4110065875282863e-44; 0.00024987101520910555 6.687159725272475e-20 … 2.362593695158234e-7 1.3046824185960588e-11], 4430.36209731353, 698)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 50\n",
    "V0 = V0full[:, 1:r]\n",
    "W0 = W0full[1:r, :]\n",
    "V, W, obj, niter = nnmf(X, r; V = V0, W = W0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHIAAAByCAAAAACqttqhAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAhVJREFUaAW9wT9LVXEAxvHvvTwmBg0N0VLSWtHe2hZC76AXcMlBGoPg0lBQTQ1tDQ69AgeDQmoUGhyCilCixcEgG+wPee858bj8LnnS4ymez0d00qPoYRVtiTgRJ+JEnIgTe/pYxeGmsVuYsKfYe9oScSJOxIk4ESf2VLS1gA0phhyNiBNxIk7EiThxRA+w+xRjjkbEiTgRJ+JEnOjkBTagCxEn4kSciBNxopPr2BZdiDgRJ+JEnIjTNew7tsLhprAduhNxIk7EiTgRpyWKm9gOtoq9xSqKS9gazaawChtT9ChEnIgTcSJOxIkJM9gKtoX1sQq7ih3D3mBjrKI4g13B+thJrI+dwkSciBNxIk7EiQnnsE3sC1Zjx7F72ACrsT5WUXzDFrEZbAG7SyHiRJyIE3EiTkzYwraxmuIidhnbxWqafcZ62DS2hi1jFzARJ+JEnIgTcWLCbewOVlG8pq0aq7Gv2Bj7gC1hIk7EiTgRJ+LEPiP+jwp7jr3ERpiIE3EiTsSJOM1hyzQ7jf3Ctulul0LEiTgRJ+JEnJ5xkBPYWewVVvOvRJyIE3EiTsSJfR5j89g6tk4xg/2grSfYCHuIiTgRJ+JEnIgT+9zA5mn2k7Zq/rSKiTgRJ+JEnIgTf1Fj77A5bBObxdZpNot9otkiJuJEnIgTcSJOHOg89hEbYQNsA6spetgjmg0pRJyIE3EiTsT9BjoHVaqLcyHxAAAAAElFTkSuQmCC",
      "text/plain": [
       "19×19 reinterpret(reshape, Gray{Float64}, ::Matrix{Float64}) with eltype Gray{Float64}:\n",
       " Gray{Float64}(2.55231e-28)  …  Gray{Float64}(8.58516e-52)\n",
       " Gray{Float64}(1.90869e-20)     Gray{Float64}(1.56411e-43)\n",
       " Gray{Float64}(3.46506e-14)     Gray{Float64}(5.2133e-37)\n",
       " Gray{Float64}(1.71962e-36)     Gray{Float64}(2.6886e-34)\n",
       " Gray{Float64}(1.45601e-40)     Gray{Float64}(6.04518e-51)\n",
       " Gray{Float64}(6.64597e-16)  …  Gray{Float64}(3.4646e-36)\n",
       " Gray{Float64}(0.301853)        Gray{Float64}(2.79333e-16)\n",
       " Gray{Float64}(1.4767)          Gray{Float64}(0.00205396)\n",
       " Gray{Float64}(1.74502)         Gray{Float64}(0.549894)\n",
       " Gray{Float64}(2.62256)         Gray{Float64}(1.30626)\n",
       " Gray{Float64}(2.93876)      …  Gray{Float64}(0.873984)\n",
       " Gray{Float64}(2.64446)         Gray{Float64}(0.402087)\n",
       " Gray{Float64}(1.60693)         Gray{Float64}(0.00514615)\n",
       " Gray{Float64}(0.286327)        Gray{Float64}(1.45863e-10)\n",
       " Gray{Float64}(3.54053e-7)      Gray{Float64}(9.79739e-11)\n",
       " Gray{Float64}(4.07595e-8)   …  Gray{Float64}(0.137673)\n",
       " Gray{Float64}(1.32083e-13)     Gray{Float64}(0.376255)\n",
       " Gray{Float64}(2.1663e-13)      Gray{Float64}(1.12898e-22)\n",
       " Gray{Float64}(2.66678e-17)     Gray{Float64}(1.17291e-79)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorview(Gray, reshape(W[5, :], 19, 19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHIAAAByCAAAAACqttqhAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAhRJREFUaAW9wb1vTXEAxvHvaR9RIRFsbhOTxlSDxaRiIoJELewGi8HWLhYJo27EX2DQxMvQtQsSCcHQBpFOBi+DNCkJt0eeu/ySc0/uvZGb5/MRPU+wcwy3jt3EJrCr2CnaLWB3KESciBNxIk7EiZ7zDHcce4NtY13sITaBdRlOxIk4ESfiRJwY2Uusws5izyi6jErEiTgRJ+JEnOhzEVum3ST2FLuNLTKqaUzEiTgRJ+JEnOizTHEY+0hxkGIBW2RUHUzEiTgRJ+JEnBjoE017+X+zmIgTcSJOxIk4VVhNO2F/KH5QrGAVVjPcA0zEiTgRJ+JEnGrsNLaBbWJT2AHsL7aOfaE4g01g37Fp7BeDiDgRJ+JEnIgTPbuxy9gF7ChNuyg+UGxj+7EtijlsDftGIeJEnIgTcSJO9NzCjjDIb+wQNkPTI2yeYpWmY5iIE3EiTsSJOE1iNYNUFBsUNVZhl7CaQW5gIk7EiTgRJ+LUwe5jdymuYfdomsXeYRVNFVbTroOJOBEn4kSciNNObAl7hb3Aatq9xyoGqbBV7ATFdUzEiTgRJ+JEnKYonjNOc7QTcSJOxIk4EafPpIk4ESfiRJyI0xZpIk7EiTgRJ+JU07QP24F9ZfxEnIgTcSJOxIk+J7El7C12BdtkPESciBNxIk7EiT6PsXnsJzaNrVFU2CRWY3uwGew11qWdiBNxIk7Eibh/TItHlEBPUckAAAAASUVORK5CYII=",
      "text/plain": [
       "19×19 reinterpret(reshape, Gray{Float64}, ::Matrix{Float64}) with eltype Gray{Float64}:\n",
       " Gray{Float64}(0.000249871)  …  Gray{Float64}(7.7835e-14)\n",
       " Gray{Float64}(6.68716e-20)     Gray{Float64}(3.17285e-28)\n",
       " Gray{Float64}(4.13413e-27)     Gray{Float64}(6.2944e-28)\n",
       " Gray{Float64}(9.70169e-27)     Gray{Float64}(0.110564)\n",
       " Gray{Float64}(1.55185e-18)     Gray{Float64}(0.214463)\n",
       " Gray{Float64}(1.6554e-10)   …  Gray{Float64}(0.394318)\n",
       " Gray{Float64}(0.00308737)      Gray{Float64}(2.77478e-9)\n",
       " Gray{Float64}(0.00177598)      Gray{Float64}(9.74163e-7)\n",
       " Gray{Float64}(0.000269407)     Gray{Float64}(2.67775e-5)\n",
       " Gray{Float64}(0.00143345)      Gray{Float64}(0.197256)\n",
       " Gray{Float64}(0.0100655)    …  Gray{Float64}(0.64495)\n",
       " Gray{Float64}(0.118806)        Gray{Float64}(0.749756)\n",
       " Gray{Float64}(0.145135)        Gray{Float64}(0.174767)\n",
       " Gray{Float64}(0.174715)        Gray{Float64}(1.97319e-9)\n",
       " Gray{Float64}(0.0426314)       Gray{Float64}(1.56859e-14)\n",
       " Gray{Float64}(0.00324005)   …  Gray{Float64}(4.59344e-15)\n",
       " Gray{Float64}(9.50824e-10)     Gray{Float64}(1.9442e-10)\n",
       " Gray{Float64}(1.76742e-13)     Gray{Float64}(2.36259e-7)\n",
       " Gray{Float64}(1.39967e-22)     Gray{Float64}(1.30468e-11)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorview(Gray, reshape(W[50, :], 19, 19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows of W are low-rank approximation of the faces from the rows of X. Compared to X, when r = 50, the images are still blurry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.7 GPU (optional)\n",
    "\n",
    "Investigate the GPU capabilities of Julia. Report the speed gain of your GPU code over CPU code at ranks $r=10, 20, 30, 40, 50$. Make sure to use the same starting point as in Q1.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Estimating Kinship Matrix\n",
    "\n",
    "Consider the numerical task of estimating an $n \\times n$ kinship matrix $\\Phi$ from an $n \\times m$ genotype matrix $\\mathbf{G}$. Here $n$ is the number of individuals and $m$ is the number of genetic markers. [Lange et al](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6763373/) derived a method of moment estimator of form\n",
    "$$\n",
    "    \\widehat \\Phi_{ij} = \\frac{e_{ij} - \\sum_{k=1}^m [p_k^2 + (1 - p_k)^2]}{m - \\sum_{k=1}^m [p_k^2 + (1 - p_k)^2]}, \\quad 1 \\le i, j \\le n,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    e_{ij} &=& \\frac{1}{4} \\sum_{k=1}^m [g_{ik} g_{jk} + (2 - g_{ik})(2 - g_{jk})] \\\\\n",
    "    p_k &=& \\frac {1}{2n} \\sum_{i=1}^n g_{ik}.\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1 Develop code\n",
    "\n",
    "Write a function that takes a matrix `G` as input and outputs the method of moment estimator. \n",
    "Make your function as efficient (both speed and memory) as possible.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kinship (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function kinship_proto(G::Matrix{T}) where T <: AbstractFloat\n",
    "    n, m = size(G)\n",
    "    # TODO: your code here\n",
    "    # pre-allocate\n",
    "    Φ = zeros(n, n)\n",
    "    E = Matrix{T}(undef, n, n) \n",
    "    vec_scaled = ones(n) ./ (2 .* n)\n",
    "    P = zeros(m)\n",
    "    Psub1 = zeros(m)\n",
    "    #G2 = similar(G)\n",
    "    #G2 .= 2 .- G\n",
    "    #@inbounds for idx in eachindex(G)\n",
    "    #    G2[idx] = 2 - G[idx]\n",
    "    #end\n",
    "    storageG = similar(E)\n",
    "    storageG2 = similar(E)\n",
    "    # assign value\n",
    "    mul!(P, transpose(G), vec_scaled)\n",
    "    Psub1 .= (1 .- P) \n",
    "    c = dot(P, P) + dot(Psub1, Psub1) # constant\n",
    "    mul!(storageG, G, transpose(G))\n",
    "    #overwrite G\n",
    "    # G .= 2 .- G \n",
    "    @inbounds for idx in eachindex(G)\n",
    "        G[idx] = 2 - G[idx]\n",
    "    end\n",
    "    mul!(storageG2, G, transpose(G))\n",
    "    E .= (storageG .+ storageG2) ./ 4\n",
    "    # output\n",
    "    Φ .= (E .- c) ./ (m - c)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kinship (generic function with 1 method)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function kinship(G::Matrix{T}) where T <: AbstractFloat\n",
    "    n, m = size(G)\n",
    "    # TODO: your code here\n",
    "    # pre-allocate\n",
    "    P = zeros(m)\n",
    "    Φ = zeros(n, n)\n",
    "    RowSums = zeros(n)\n",
    "    ones_n = ones(n)\n",
    "    mul!(Φ, G, transpose(G))\n",
    "    mul!(P, transpose(G), ones_n ./ (2 * n))\n",
    "    sum!(RowSums, G)\n",
    "    Φ .= (Φ .- (RowSums .+ transpose(RowSums))) ./ 2 \n",
    "    c = 2dot(P, P) - 2sum(P)  # constant\n",
    "    Φ .= (Φ .- c) ./ c\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×10000 Matrix{Float64}:\n",
       " 1.0  0.0  2.0  0.0  0.0  2.0  2.0  2.0  …  2.0  0.0  0.0  2.0  2.0  2.0  1.0\n",
       " 2.0  2.0  1.0  2.0  0.0  0.0  1.0  0.0     2.0  2.0  0.0  1.0  2.0  2.0  1.0\n",
       " 1.0  0.0  2.0  1.0  1.0  1.0  2.0  0.0     0.0  1.0  1.0  0.0  1.0  2.0  0.0\n",
       " 2.0  0.0  1.0  0.0  0.0  1.0  1.0  2.0     1.0  1.0  0.0  2.0  0.0  2.0  1.0\n",
       " 1.0  2.0  1.0  2.0  2.0  1.0  0.0  0.0     1.0  1.0  1.0  2.0  1.0  1.0  0.0\n",
       " 1.0  0.0  1.0  2.0  0.0  1.0  1.0  1.0  …  2.0  0.0  0.0  2.0  0.0  1.0  2.0\n",
       " 2.0  2.0  1.0  1.0  0.0  1.0  1.0  1.0     1.0  1.0  1.0  2.0  1.0  0.0  2.0\n",
       " 2.0  2.0  1.0  1.0  1.0  1.0  2.0  1.0     2.0  1.0  2.0  2.0  0.0  0.0  1.0\n",
       " 2.0  1.0  1.0  2.0  0.0  0.0  2.0  2.0     0.0  0.0  1.0  0.0  2.0  2.0  0.0\n",
       " 0.0  1.0  2.0  0.0  0.0  2.0  1.0  1.0     2.0  1.0  0.0  0.0  0.0  2.0  1.0\n",
       " 2.0  2.0  1.0  1.0  1.0  2.0  1.0  0.0  …  1.0  1.0  2.0  0.0  1.0  1.0  2.0\n",
       " 2.0  1.0  0.0  0.0  2.0  0.0  1.0  2.0     0.0  0.0  2.0  1.0  2.0  1.0  2.0\n",
       " 1.0  2.0  2.0  2.0  0.0  1.0  2.0  0.0     0.0  0.0  0.0  1.0  2.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱            ⋮                   \n",
       " 0.0  1.0  0.0  1.0  0.0  0.0  1.0  2.0     0.0  2.0  2.0  0.0  2.0  0.0  2.0\n",
       " 1.0  1.0  1.0  1.0  0.0  1.0  1.0  2.0     1.0  1.0  2.0  2.0  1.0  1.0  2.0\n",
       " 2.0  2.0  2.0  1.0  1.0  2.0  0.0  0.0  …  2.0  2.0  0.0  0.0  0.0  2.0  2.0\n",
       " 2.0  0.0  2.0  0.0  2.0  0.0  0.0  1.0     0.0  1.0  1.0  2.0  1.0  2.0  2.0\n",
       " 1.0  1.0  1.0  0.0  2.0  1.0  0.0  0.0     2.0  1.0  2.0  1.0  1.0  0.0  0.0\n",
       " 0.0  2.0  2.0  0.0  2.0  2.0  2.0  1.0     1.0  1.0  1.0  1.0  0.0  2.0  1.0\n",
       " 2.0  2.0  0.0  2.0  2.0  0.0  0.0  0.0     2.0  0.0  1.0  1.0  1.0  2.0  1.0\n",
       " 0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  …  2.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  2.0  2.0  1.0  2.0  0.0  2.0     2.0  0.0  1.0  0.0  2.0  0.0  0.0\n",
       " 0.0  2.0  0.0  2.0  0.0  2.0  2.0  1.0     2.0  1.0  2.0  2.0  1.0  2.0  2.0\n",
       " 1.0  2.0  2.0  0.0  0.0  2.0  2.0  0.0     1.0  0.0  1.0  0.0  0.0  2.0  1.0\n",
       " 1.0  0.0  2.0  0.0  2.0  0.0  2.0  2.0     2.0  2.0  0.0  2.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(257)\n",
    "G = rand(0.0:2.0, 1000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000-element Vector{Float64}:\n",
       " 0.4905000000000003\n",
       " 0.5025000000000004\n",
       " 0.49500000000000033\n",
       " 0.5095000000000003\n",
       " 0.47950000000000037\n",
       " 0.49700000000000033\n",
       " 0.5020000000000003\n",
       " 0.4935000000000004\n",
       " 0.4875000000000004\n",
       " 0.4920000000000003\n",
       " 0.49650000000000033\n",
       " 0.5090000000000003\n",
       " 0.4810000000000003\n",
       " ⋮\n",
       " 0.4880000000000003\n",
       " 0.4835000000000004\n",
       " 0.4945000000000004\n",
       " 0.49850000000000033\n",
       " 0.49600000000000033\n",
       " 0.4870000000000003\n",
       " 0.5070000000000003\n",
       " 0.5025000000000004\n",
       " 0.49700000000000033\n",
       " 0.5100000000000003\n",
       " 0.5000000000000003\n",
       " 0.47650000000000037"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = size(G)\n",
    "    # TODO: your code here\n",
    "    # pre-allocate\n",
    "P = zeros(m)\n",
    "ones_n = ones(n)\n",
    "ones_m = ones(m)\n",
    "mul!(P, transpose(G), ones_n ./ (2 * n))\n",
    "#m - 2sum(P) + 2dot(P, P)\n",
    "#c = m - 2 * dot(ones_m, P) + 2 * dot(P, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1 = G[1:5, 1:5]\n",
    "t = zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " 3.0\n",
       " 7.0\n",
       " 5.0\n",
       " 3.0\n",
       " 8.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sum(g1, dims = 2)\n",
    "sum!(t, g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Vector{Float64}:\n",
       " 10006.0\n",
       "  9984.0\n",
       " 10117.0\n",
       "  9905.0\n",
       "  9930.0\n",
       " 10084.0\n",
       " 10051.0\n",
       " 10000.0\n",
       "  9941.0\n",
       " 10068.0\n",
       " 10211.0\n",
       " 10048.0\n",
       "  9856.0\n",
       "     ⋮\n",
       "  9946.0\n",
       "  9951.0\n",
       " 10122.0\n",
       " 10041.0\n",
       "  9991.0\n",
       "  9979.0\n",
       " 10087.0\n",
       " 10015.0\n",
       "  9939.0\n",
       " 10003.0\n",
       "  9972.0\n",
       " 10163.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vstorage = zeros(n)\n",
    "sum!(Vstorage, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×1000 Matrix{Float64}:\n",
       " 20012.0  19990.0  20123.0  19911.0  …  19945.0  20009.0  19978.0  20169.0\n",
       " 19990.0  19968.0  20101.0  19889.0     19923.0  19987.0  19956.0  20147.0\n",
       " 20123.0  20101.0  20234.0  20022.0     20056.0  20120.0  20089.0  20280.0\n",
       " 19911.0  19889.0  20022.0  19810.0     19844.0  19908.0  19877.0  20068.0\n",
       " 19936.0  19914.0  20047.0  19835.0     19869.0  19933.0  19902.0  20093.0\n",
       " 20090.0  20068.0  20201.0  19989.0  …  20023.0  20087.0  20056.0  20247.0\n",
       " 20057.0  20035.0  20168.0  19956.0     19990.0  20054.0  20023.0  20214.0\n",
       " 20006.0  19984.0  20117.0  19905.0     19939.0  20003.0  19972.0  20163.0\n",
       " 19947.0  19925.0  20058.0  19846.0     19880.0  19944.0  19913.0  20104.0\n",
       " 20074.0  20052.0  20185.0  19973.0     20007.0  20071.0  20040.0  20231.0\n",
       " 20217.0  20195.0  20328.0  20116.0  …  20150.0  20214.0  20183.0  20374.0\n",
       " 20054.0  20032.0  20165.0  19953.0     19987.0  20051.0  20020.0  20211.0\n",
       " 19862.0  19840.0  19973.0  19761.0     19795.0  19859.0  19828.0  20019.0\n",
       "     ⋮                               ⋱                             \n",
       " 19952.0  19930.0  20063.0  19851.0     19885.0  19949.0  19918.0  20109.0\n",
       " 19957.0  19935.0  20068.0  19856.0     19890.0  19954.0  19923.0  20114.0\n",
       " 20128.0  20106.0  20239.0  20027.0  …  20061.0  20125.0  20094.0  20285.0\n",
       " 20047.0  20025.0  20158.0  19946.0     19980.0  20044.0  20013.0  20204.0\n",
       " 19997.0  19975.0  20108.0  19896.0     19930.0  19994.0  19963.0  20154.0\n",
       " 19985.0  19963.0  20096.0  19884.0     19918.0  19982.0  19951.0  20142.0\n",
       " 20093.0  20071.0  20204.0  19992.0     20026.0  20090.0  20059.0  20250.0\n",
       " 20021.0  19999.0  20132.0  19920.0  …  19954.0  20018.0  19987.0  20178.0\n",
       " 19945.0  19923.0  20056.0  19844.0     19878.0  19942.0  19911.0  20102.0\n",
       " 20009.0  19987.0  20120.0  19908.0     19942.0  20006.0  19975.0  20166.0\n",
       " 19978.0  19956.0  20089.0  19877.0     19911.0  19975.0  19944.0  20135.0\n",
       " 20169.0  20147.0  20280.0  20068.0     20102.0  20166.0  20135.0  20326.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vstorage .+ transpose(Vstorage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 Correctness\n",
    "\n",
    "First let's make sure our function yields correct answer. Run your function on a fake genotype matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×1000 Matrix{Float64}:\n",
       " -0.673584      0.000762864   0.00266412   …  -0.0108448     0.00446532\n",
       "  0.000762864  -0.665178      0.0101691       -0.00994423    0.00136326\n",
       "  0.00266412    0.0101691    -0.665078         0.0157728     0.00356472\n",
       " -0.00343992    0.0110697    -0.0102444       -0.0106447    -0.00514105\n",
       " -0.00293959   -0.00223912   -0.00253932       0.00506571   -0.00163873\n",
       "  0.00226386    0.00626651    0.00876817   …  -0.00834317   -0.00494091\n",
       " -0.00684217    0.00516578   -0.00384018       0.00486558   -0.00604164\n",
       " -0.00404032   -0.00524111    0.00816777       0.00236392    0.00696697\n",
       " -0.000237799  -0.00233919   -0.0129462        0.0012632     0.00296432\n",
       " -0.00564138    0.00366479   -0.0108448        0.00736724   -0.0154479\n",
       " -0.00574144    0.00606638   -0.00203899   …  -0.00273946    0.00736724\n",
       "  0.00326452    0.00856803    0.000162467     -0.00183886    0.0089683\n",
       " -0.000638064  -0.00293959    0.00306439       0.00496565    0.00156339\n",
       "  ⋮                                        ⋱                \n",
       " -0.0122458     0.000962997   0.0106694        0.00476552   -0.00173879\n",
       "  0.00466545   -0.0150476    -0.00073813      -0.00454065    0.00306439\n",
       " -0.00193893   -0.00273946   -0.012546     …  -0.00384018   -0.00414038\n",
       " -0.00754264   -0.0128461     0.00106306      -0.0088435    -0.00474078\n",
       "  0.00246399    0.00396499    0.00506571       0.0095687     0.00406505\n",
       "  0.00646664   -0.00353999    0.00146333       0.0111698    -0.00203899\n",
       "  0.012971      0.0112698     0.00206373       0.00756737    0.0198755\n",
       "  0.00206373   -0.00654197   -0.00404032   …  -0.00253932    0.00466545\n",
       " -0.0135466    -0.00524111   -0.00143859      -0.000437931  -0.00584151\n",
       " -0.000938262  -0.000137732   0.00476552      -0.000337865   0.00186359\n",
       " -0.0108448    -0.00994423    0.0157728       -0.665378      0.0109696\n",
       "  0.00446532    0.00136326    0.00356472       0.0109696    -0.665478"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a fake genotype matrix with entries {0, 1, 2}\n",
    "Random.seed!(257)\n",
    "G = rand(0.0:2.0, 1000, 10000)\n",
    "Φ = kinship(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the upper left $5 \\times 5$ block to what I got using my implementation\n",
    "\n",
    "```julia\n",
    "Φ[1:5, 1:5]\n",
    "```\n",
    "\n",
    "```\n",
    "5×5 Matrix{Float64}:\n",
    "  0.673584     -0.000762864  -0.00266412   0.00343992   0.00293959\n",
    " -0.000762864   0.665178     -0.0101691   -0.0110697    0.00223912\n",
    " -0.00266412   -0.0101691     0.665078     0.0102444    0.00253932\n",
    "  0.00343992   -0.0110697     0.0102444    0.66768     -0.0083679\n",
    "  0.00293959    0.00223912    0.00253932  -0.0083679    0.663777\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Matrix{Float64}:\n",
       " -0.673584      0.000762864   0.00266412  -0.00343992  -0.00293959\n",
       "  0.000762864  -0.665178      0.0101691    0.0110697   -0.00223912\n",
       "  0.00266412    0.0101691    -0.665078    -0.0102444   -0.00253932\n",
       " -0.00343992    0.0110697    -0.0102444   -0.66768      0.0083679\n",
       " -0.00293959   -0.00223912   -0.00253932   0.0083679   -0.663777"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Φ[1:5, 1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3 Efficiency\n",
    "\n",
    "In a typical genetic data set, $n$ is at order of $10^3 \\sim 10^6$ and $m$ is at order of $10^6 \\sim 10^7$. Benchmark your function using the smaller data set $G$ generated in Q2.2. Efficiency (both speed and memory) will be the most important criterion when grading this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  254.416 ms (7 allocations: 7.73 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000×1000 Matrix{Float64}:\n",
       " -0.673584      0.000762864   0.00266412   …  -0.0108448     0.00446532\n",
       "  0.000762864  -0.665178      0.0101691       -0.00994423    0.00136326\n",
       "  0.00266412    0.0101691    -0.665078         0.0157728     0.00356472\n",
       " -0.00343992    0.0110697    -0.0102444       -0.0106447    -0.00514105\n",
       " -0.00293959   -0.00223912   -0.00253932       0.00506571   -0.00163873\n",
       "  0.00226386    0.00626651    0.00876817   …  -0.00834317   -0.00494091\n",
       " -0.00684217    0.00516578   -0.00384018       0.00486558   -0.00604164\n",
       " -0.00404032   -0.00524111    0.00816777       0.00236392    0.00696697\n",
       " -0.000237799  -0.00233919   -0.0129462        0.0012632     0.00296432\n",
       " -0.00564138    0.00366479   -0.0108448        0.00736724   -0.0154479\n",
       " -0.00574144    0.00606638   -0.00203899   …  -0.00273946    0.00736724\n",
       "  0.00326452    0.00856803    0.000162467     -0.00183886    0.0089683\n",
       " -0.000638064  -0.00293959    0.00306439       0.00496565    0.00156339\n",
       "  ⋮                                        ⋱                \n",
       " -0.0122458     0.000962997   0.0106694        0.00476552   -0.00173879\n",
       "  0.00466545   -0.0150476    -0.00073813      -0.00454065    0.00306439\n",
       " -0.00193893   -0.00273946   -0.012546     …  -0.00384018   -0.00414038\n",
       " -0.00754264   -0.0128461     0.00106306      -0.0088435    -0.00474078\n",
       "  0.00246399    0.00396499    0.00506571       0.0095687     0.00406505\n",
       "  0.00646664   -0.00353999    0.00146333       0.0111698    -0.00203899\n",
       "  0.012971      0.0112698     0.00206373       0.00756737    0.0198755\n",
       "  0.00206373   -0.00654197   -0.00404032   …  -0.00253932    0.00466545\n",
       " -0.0135466    -0.00524111   -0.00143859      -0.000437931  -0.00584151\n",
       " -0.000938262  -0.000137732   0.00476552      -0.000337865   0.00186359\n",
       " -0.0108448    -0.00994423    0.0157728       -0.665378      0.0109696\n",
       "  0.00446532    0.00136326    0.00356472       0.0109696    -0.665478"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# benchmark\n",
    "@btime kinship($G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**: I got `@btime` output\n",
    "```\n",
    "82.144 ms (3 allocations: 7.64 MiB)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Count  Overhead File                    Line Function\n",
      " =====  ======== ====                    ==== ========\n",
      "    17         0 In[50]                     5 kinship(G::Matrix{Float64})\n",
      "   337         0 In[50]                     6 kinship(G::Matrix{Float64})\n",
      "     1         0 In[50]                     7 kinship(G::Matrix{Float64})\n",
      "    42         0 In[50]                     8 kinship(G::Matrix{Float64})\n",
      "    73         0 In[50]                     9 kinship(G::Matrix{Float64})\n",
      "     1         0 In[50]                    10 kinship(G::Matrix{Float64})\n",
      "    17         0 In[50]                    11 kinship(G::Matrix{Float64})\n",
      "    49         0 In[50]                    13 kinship(G::Matrix{Float64})\n",
      "    14         0 In[50]                    14 kinship(G::Matrix{Float64})\n",
      "    28         0 In[50]                    16 kinship(G::Matrix{Float64})\n",
      "   579         0 In[54]                     3 macro expansion\n",
      "   172         0 @Base/array.jl           353 fill!\n",
      "     4         4 @Base/array.jl           861 getindex\n",
      "    10        10 @Base/array.jl           862 getindex\n",
      "     1         0 @Base/array.jl           520 ones\n",
      "     1         0 @Base/array.jl           522 ones\n",
      "     1         0 @Base/array.jl           526 ones\n",
      "   178       178 @Base/array.jl           903 setindex!\n",
      "    41        41 @Base/array.jl           905 setindex!\n",
      "   470         0 @Base/array.jl           520 zeros\n",
      "   470         0 @Base/array.jl           522 zeros\n",
      "   299         0 @Base/array.jl           525 zeros\n",
      "   171         0 @Base/array.jl           526 zeros\n",
      "   299       299 @Base/boot.jl            459 Array\n",
      "   299         0 @Base/boot.jl            467 Array\n",
      "   579         0 @Base/boot.jl            373 eval\n",
      "     9         0 @Base/broadcast.jl       636 _broadcast_getindex\n",
      "     9         0 @Base/broadcast.jl       642 _broadcast_getindex\n",
      "     1         0 @Base/broadcast.jl       643 _broadcast_getindex\n",
      "     1         0 @Base/broadcast.jl       670 _broadcast_getindex_evalf\n",
      "     9         0 @Base/broadcast.jl       666 _getindex\n",
      "    42         0 @Base/broadcast.jl       913 copyto!\n",
      "    42         0 @Base/broadcast.jl       960 copyto!\n",
      "    10         0 @Base/broadcast.jl       597 getindex\n",
      "    36         0 @Base/broadcast.jl       961 macro expansion\n",
      "    42         0 @Base/broadcast.jl       868 materialize!\n",
      "    42         0 @Base/broadcast.jl       871 materialize!\n",
      "   579         0 @Base/essentials.jl      716 #invokelatest#2\n",
      "   579         0 @Base/essentials.jl      714 invokelatest\n",
      "    39        39 @Base/float.jl           399 +\n",
      "     1         1 @Base/float.jl           408 /\n",
      "     6         6 @Base/int.jl              87 +\n",
      "   579         0 @Base/loading.jl        1196 include_string(mapexpr::typeof(...\n",
      "    13         0 ...multidimensional.jl   644 getindex\n",
      "    32         0 ...multidimensional.jl   646 setindex!\n",
      "     1         1 @Base/promotion.jl       468 ==\n",
      "     1         0 @Base/range.jl           837 iterate\n",
      "    39         0 @Base/reduce.jl           27 add_sum\n",
      "    49         0 @Base/reducedim.jl       911 #sum!#752\n",
      "    49         0 @Base/reducedim.jl       913 #sum!#753\n",
      "    49         0 @Base/reducedim.jl       281 _mapreducedim!(f::typeof(identi...\n",
      "    49         0 @Base/reducedim.jl       282 macro expansion\n",
      "    49         0 @Base/reducedim.jl       289 mapreducedim!\n",
      "    49         0 @Base/reducedim.jl       913 sum!\n",
      "    49         0 @Base/reducedim.jl       911 sum!##kw\n",
      "    85         0 @Base/simdloop.jl         77 macro expansion\n",
      "     6         0 @Base/simdloop.jl         78 macro expansion\n",
      "   579         0 @Base/task.jl            423 (::IJulia.var\"#15#18\")()\n",
      "   579         0 ...ia/src/eventloop.jl     8 eventloop(socket::ZMQ.Socket)\n",
      "   579         0 .../execute_request.jl    67 execute_request(socket::ZMQ.Soc...\n",
      "   579         0 .../SoftGlobalScope.jl    65 softscope_include_string(m::Mod...\n",
      "    17         0 ...gebra/src/matmul.jl   510 copytri!\n",
      "    17         0 ...gebra/src/matmul.jl   514 copytri!\n",
      "    17         0 ...gebra/src/matmul.jl   275 mul!\n",
      "    17         0 ...gebra/src/matmul.jl   390 mul!\n",
      "    17         0 ...gebra/src/matmul.jl   582 syrk_wrapper!(C::Matrix{Float64...\n",
      "   579         0 ...file/src/Profile.jl    28 top-level scope\n",
      "Total snapshots: 2448\n"
     ]
    }
   ],
   "source": [
    "using Profile\n",
    "Profile.clear()\n",
    "@profile for i in 1:10; kinship(G); end\n",
    "Profile.print(format=:flat)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "87px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
